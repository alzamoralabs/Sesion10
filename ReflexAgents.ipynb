{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f155d1",
   "metadata": {},
   "source": [
    "# Simple Reflex Agent\n",
    "Los simple reflex agents son programas que toman decisiones basadas únicamente en la información actual que reciben del entorno (percept), sin considerar el historial de percepciones pasadas. Funcionan siguiendo reglas de tipo \"if-then\" (si-entonces) para reaccionar de manera inmediata a los estímulos, pero no pueden planificar ni aprender de experiencias previas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50f6be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to copy 'C:\\\\Users\\\\Bo\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\venv\\\\scripts\\\\nt\\\\venvlauncher.exe' to 'c:\\\\gitprojects\\\\ses10\\\\venv\\\\Scripts\\\\python.exe'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in .\\venv\\lib\\site-packages (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement random (from versions: none)\n",
      "ERROR: No matching distribution found for random\n"
     ]
    }
   ],
   "source": [
    "!python -m venv venv || source venvnb2\\Scripts\\activate\n",
    "!pip install ollama random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50e3ef",
   "metadata": {},
   "source": [
    "En el ejemplo siguiente, se implementa un agente reflexivo simple que toma decisiones basadas únicamente en la percepción actual del entorno.\n",
    "\n",
    "El agente recibe como entrada un diccionario con valores de temperatura y presión, y utiliza un conjunto de reglas de tipo \"si-entonces\" para determinar la acción a realizar (por ejemplo, encender o apagar la calefacción, activar o desactivar una bomba).\n",
    "\n",
    "El agente evalúa cada regla y ejecuta la acción correspondiente si se cumple la condición, sin considerar el historial de percepciones previas ni mantener un modelo interno del entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "115df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ollama\n",
    "\n",
    "# Reglas de condición-acción\n",
    "reglas = {\n",
    "    \"temperatura < 18\": \"encender calefacción\",\n",
    "    \"temperatura > 24\": \"apagar calefacción\",\n",
    "    \"presión < 30\": \"activar bomba\",\n",
    "    \"presión > 70\": \"desactivar bomba\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c2c1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar condiciones simples\n",
    "def cumple_condicion(percepcion, condicion):\n",
    "    variable, operador, valor = condicion.split()\n",
    "    valor = float(valor)\n",
    "    entrada = percepcion.get(variable)\n",
    "\n",
    "    if entrada is None:\n",
    "        return False\n",
    "\n",
    "    if operador == \"<\":\n",
    "        return entrada < valor\n",
    "    elif operador == \">\":\n",
    "        return entrada > valor\n",
    "    elif operador == \"==\":\n",
    "        return entrada == valor\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Simple Reflex Agent\n",
    "def agente_reflejo_simple(percepcion):\n",
    "    for condicion, accion in reglas.items():\n",
    "        if cumple_condicion(percepcion, condicion):\n",
    "            print(f\"Acción local: {accion}\")\n",
    "            return accion\n",
    "\n",
    "    print(\"Sin acción necesaria.\")\n",
    "    return \"sin acción\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "451553a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percepción actual: {'temperatura': 16, 'presión': 30}\n",
      "Acción local: encender calefacción\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "percepcion_actual = {\n",
    "    \"temperatura\": random.randint(10, 35), #15 in Celsius\n",
    "    \"presión\": random.randint(20, 80) #45 in PSI\n",
    "}\n",
    "print(f\"Percepción actual: {percepcion_actual}\")\n",
    "accion_tomada = agente_reflejo_simple(percepcion_actual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42ed8d",
   "metadata": {},
   "source": [
    "# Model Based Reflex Agent\n",
    "Un Model Based Reflex Agent es un agente que, además de reaccionar a los estímulos actuales (percepts), mantiene un modelo interno (model) del estado del entorno. Esto le permite tomar decisiones considerando no solo la percepción inmediata, sino también información sobre cómo el entorno puede cambiar con el tiempo. Así, puede manejar situaciones donde la percepción actual no es suficiente para decidir la acción correcta, usando su modelo para inferir el estado real del entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c5b78ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in .\\venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_ollama in .\\venv\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain-openai in .\\venv\\lib\\site-packages (0.3.35)\n",
      "Requirement already satisfied: python-dotenv in .\\venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in .\\venv\\lib\\site-packages (from langchain) (0.3.78)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in .\\venv\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in .\\venv\\lib\\site-packages (from langchain) (0.4.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\venv\\lib\\site-packages (from langchain) (2.12.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\venv\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\venv\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in .\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in .\\venv\\lib\\site-packages (from langchain_ollama) (0.6.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in .\\venv\\lib\\site-packages (from langchain-openai) (2.2.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in .\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\venv\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\venv\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in .\\venv\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in .\\venv\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.9.18)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.104.2->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_ollama langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0894c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "27123713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "# Configuración del LLM local con Ollama y modelo llama3.2\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "system_prompt = \"\"\"Eres asistente inteligente de banca y finanzas.\n",
    "Que decide la mejor acción en base a el estado actual de tu cliente.\n",
    "Las acciones que puedes tomar son:\n",
    "- mostrar saldo de cuenta ** esta no requiere confirmación del cliente **\n",
    "- transferir dinero ** esta requiere confirmación del cliente **\n",
    "- pagar factura ** esta requiere confirmación del cliente **\n",
    "- invertir ** esta requiere confirmación del cliente **\n",
    "** cuando estes a punto de realizar una acción, primero pregunta si el cliente desea proceder con la acción. De esa forma evitas acciones no deseadas y recoges el feedback del cliente. **\n",
    "Tomas en cuenta tu historial de de tus acciones y confirmas si tu cliente decidio proceder o no con la accion que sugieras.\n",
    "- cuando identifiques la accion a tomar, responde ademas con la accion en minusculas y sin puntuacion. Si no hay ninguna accion a tomar, responde \"ninguna\".\n",
    "    por ejemplo:\n",
    "    Accion tomada por agente: mostrar saldo de cuenta\n",
    "- cuando identifiques el feedback del cliente, responde ademas con el feedback en minusculas y sin puntuacion.\n",
    "    Por ejemplo:\n",
    "    Feedback del cliente: si, deseo proceder con la accion\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c7e1d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "state_map = {}\n",
    "\n",
    "class State:\n",
    "    def __init__(self, query, status, timestamp):\n",
    "        self.input = user_query\n",
    "        self.action = agent_action\n",
    "        self.feedback = user_feedback\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "feedback_prompt = (\n",
    "            \"\"\"Devuelve un JSON estructurado con los siguientes campos: 'query_usuario', 'accion_sugerida', 'feedback_usuario'.\n",
    "            el historico de conversacion es: {history}\"\"\"\n",
    "        )\n",
    "feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(feedback_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"),\n",
    "])\n",
    "\n",
    "feedback_pipeline = feedback_prompt | llm \n",
    "\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in state_map:\n",
    "        # Si no existe, crea un nuevo historial de chat en memoria\n",
    "        state_map[session_id] = InMemoryChatMessageHistory()\n",
    "        return state_map[session_id]\n",
    "    response = feedback_pipeline.invoke({\"history\": state_map[session_id].messages})\n",
    "    state_map[session_id].add_ai_message(str(response))\n",
    "    return state_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c28626b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "59b52af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puedo mostrar tu saldo de cuenta.\n"
     ]
    }
   ],
   "source": [
    "reply = pipeline_with_history.invoke(\n",
    "    {\"query\": \"hola, cual es mi saldo actual?\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc13da4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'history'}.  Expected: ['history'] Received: ['{history}']\\nNote: if you intended {history} to be part of the string and not a variable, please escape it with double curly braces like: '{{history}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reply = \u001b[43mpipeline_with_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSi, solo ver mi saldo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msession_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid_123\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(reply)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5713\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5705\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5706\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5709\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5710\u001b[39m ) -> Output:\n\u001b[32m   5711\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.invoke(\n\u001b[32m   5712\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m5713\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   5714\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5715\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\runnables\\history.py:598\u001b[39m, in \u001b[36mRunnableWithMessageHistory._merge_configs\u001b[39m\u001b[34m(self, *configs)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expected_keys) == \u001b[32m1\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parameter_names:\n\u001b[32m    597\u001b[39m         \u001b[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m         message_history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_session_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    602\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[152]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mget_chat_history\u001b[39m\u001b[34m(session_id)\u001b[39m\n\u001b[32m     25\u001b[39m     state_map[session_id] = InMemoryChatMessageHistory()\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m state_map[session_id]\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mfeedback_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{history}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m state_map[session_id].add_ai_message(\u001b[38;5;28mstr\u001b[39m(response))\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state_map[session_id]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3244\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3244\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3245\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3246\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:214\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    213\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2092\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2088\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2089\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2090\u001b[39m         output = cast(\n\u001b[32m   2091\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2092\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2094\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2096\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2098\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2099\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2100\u001b[39m         )\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2102\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:187\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     inner_input_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**inner_input_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\gitprojects\\ses10\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:181\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    175\u001b[39m     example_key = missing.pop()\n\u001b[32m    176\u001b[39m     msg += (\n\u001b[32m    177\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    182\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to ChatPromptTemplate is missing variables {'history'}.  Expected: ['history'] Received: ['{history}']\\nNote: if you intended {history} to be part of the string and not a variable, please escape it with double curly braces like: '{{history}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "reply = pipeline_with_history.invoke(\n",
    "    {\"query\": \"Si, solo ver mi saldo\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "802d76d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Accion tomada: ninguna\n",
      "Feedback del cliente: ninguno\n",
      "**accion tomada por agente:** invertir\n",
      "**respuesta del cliente:** no, el cliente no ha especificado una cantidad de dinero para invertir.\n",
      "**historial de acciones:** \n",
      "- mostrar saldo de cuenta \n",
      "- transferir dinero: si, deseo proceder con la accion. \n",
      "- pagar factura: no, el cliente no ha especificado una factura pendiente.\n",
      "- pagar factura\n",
      "**respuesta del cliente:** no, el cliente no ha especificado una factura pendiente.\n",
      "**acciones sugeridas para el futuro:** \n",
      "- transferir dinero\n"
     ]
    }
   ],
   "source": [
    "reply = pipeline_with_history.invoke(\n",
    "    {\"query\": \"Quiero invertir 5000 dolares en acciones tecnológicas.\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "56901b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Accion tomada: ninguna\n",
      "Feedback del cliente: ninguno\n",
      "**Historial de Acciones Tomadas**\n",
      "\n",
      "*   Inicialmente, sugerí verificar el saldo actual de tu cuenta, lo cual ya habíamos realizado.\n",
      "*   Luego, propuse invertir una parte de tu saldo actual en una cartera diversificada para maximizar tus ganancias. El cliente se mostró interesado en realizar esta acción pero finalmente cambió su opinión y ahora quiere invertir $5,000 en acciones tecnológicas.\n",
      "\n",
      "**Nueva Acción Sugerida**\n",
      "\n",
      "Considerando que el cliente ha expresado su deseo de invertir en acciones tecnológicas, te sugiero seguir adelante con la inversión.\n",
      "\n",
      "**Recomendaciones Adicionales**\n",
      "\n",
      "Antes de proceder con la inversión, me aseguraré de verificar algunos requisitos importantes:\n",
      "\n",
      "*   **Objetivo de Inversión**: ¿Cuál es tu objetivo de inversión? ¿Estás buscando ganancias a corto plazo o a largo plazo?\n",
      "*   **Riesgo Tolerancia**: ¿Cuánto riesgo estás dispuesto a asumir con tus inversiones?\n",
      "*   **Diversificación**: ¿Tienes una cartera diversificada de inversiones en diferentes activos, como acciones, bonos y bienes raíces?\n",
      "\n",
      "**Preguntando al Cliente:**\n",
      "\n",
      "Antes de proceder con la acción sugerida, ¿estás seguro de que deseas invertir un parte de tu saldo actual?\n"
     ]
    }
   ],
   "source": [
    "reply = pipeline_with_history.invoke(\n",
    "    {\"query\": \"Si, procede.\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "57a34148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: hola, cual es mi saldo actual?\n",
      "ai: Hola! Me alegra ayudarte con tu pregunta sobre el saldo actual de tu cuenta.\n",
      "\n",
      "**Saldo Actual:** Se ha verificado tu saldo actual. Tu saldo actual es de $10,500.00.\n",
      "\n",
      "¿Quieres realizar alguna otra acción o verificar algo más?\n",
      "ai: ```json\n",
      "{\n",
      "  \"feedback\": {\n",
      "    \"accion_sugerida\": \"Ninguna\",\n",
      "    \"confirmacion_cliente\": false\n",
      "  }\n",
      "}\n",
      "```\n",
      "Esto significa que el cliente ha expresado su desacuerdo con la acción sugerida, ya que no hay ninguna acción sugerida.\n",
      "human: Si, y si es muy alto, que puedo hacer?\n",
      "ai: **Sugerencia de Acción:** Considerando tu saldo actual de $10,500.00, podrías considerar invertir en una cartera diversificada para maximizar tus ganancias.\n",
      "\n",
      "**Preguntando al cliente:**\n",
      "Antes de proceder con la acción sugerida, ¿estás seguro de que deseas invertir un parte de tu saldo actual?\n",
      "ai: ```json\n",
      "{\n",
      "  \"acción_sugerida\": \"\",\n",
      "  \"confirmación_cliente\": false\n",
      "}\n",
      "```\n",
      "\n",
      "Este JSON representa la estructura deseada con el campo 'acción_sugerida' vacío porque, según la información proporcionada, no se sugirió ninguna acción. El campo 'confirmación_cliente' también está establecido en `false` debido a que el feedback del cliente es \"ninguno\".\n",
      "human: Quiero invertir 5000 dolares en acciones tecnológicas.\n",
      "ai: **Verificación de la Acción Sugerida**\n",
      "\n",
      "Antes de proceder con la acción de invertir $5,000 en acciones tecnológicas, me aseguraré de verificar algunos requisitos importantes.\n",
      "\n",
      "*   **Objetivo de Inversión**: ¿Cuál es tu objetivo de inversión? ¿Estás buscando ganancias a corto plazo o a largo plazo?\n",
      "*   **Riesgo Tolerancia**: ¿Cuánto riesgo estás dispuesto a asumir con tus inversiones?\n",
      "*   **Diversificación**: ¿Tienes una cartera diversificada de inversiones en diferentes activos, como acciones, bonos y bienes raíces?\n",
      "\n",
      "**Recomendación**\n",
      "\n",
      "Una vez que tenga más información sobre tus objetivos de inversión, tolerancia al riesgo y estrategia de diversificación, puedo ofrecerte recomendaciones personalizadas para tu caso específico.\n",
      "\n",
      "Sin embargo, en este momento, puedo decirte que invertir $5,000 en acciones tecnológicas puede ser una opción a considerar, pero es importante tener en cuenta la volatilidad del mercado y los riesgos asociados con las inversiones en esta industria.\n",
      "ai: ```json\n",
      "{\n",
      "  \"accion_sugerida\": \"\",\n",
      "  \"confirmacion_cliente\": false\n",
      "}\n",
      "```\n",
      "\n",
      "Espero haber cumplido con tus instrucciones. Si necesitas algo más, no dudes en preguntar.\n",
      "ai: Aquí tienes un ejemplo de cómo podrías estructurar este feedback en formato JSON:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"accion_sugerida\": \"\",\n",
      "  \"confirmacion_cliente\": false\n",
      "}\n",
      "```\n",
      "\n",
      "En este ejemplo, se indican que no se tomó ninguna acción y el cliente confirmó que no había nada que hacer.\n",
      "human: Si, procede.\n",
      "ai: **Historial de Acciones Tomadas**\n",
      "\n",
      "*   Inicialmente, sugerí verificar el saldo actual de tu cuenta, lo cual ya habíamos realizado.\n",
      "*   Luego, propuse invertir una parte de tu saldo actual en una cartera diversificada para maximizar tus ganancias. El cliente se mostró interesado en realizar esta acción pero finalmente cambió su opinión y ahora quiere invertir $5,000 en acciones tecnológicas.\n",
      "\n",
      "**Nueva Acción Sugerida**\n",
      "\n",
      "Considerando que el cliente ha expresado su deseo de invertir en acciones tecnológicas, te sugiero seguir adelante con la inversión.\n",
      "\n",
      "**Recomendaciones Adicionales**\n",
      "\n",
      "Antes de proceder con la inversión, me aseguraré de verificar algunos requisitos importantes:\n",
      "\n",
      "*   **Objetivo de Inversión**: ¿Cuál es tu objetivo de inversión? ¿Estás buscando ganancias a corto plazo o a largo plazo?\n",
      "*   **Riesgo Tolerancia**: ¿Cuánto riesgo estás dispuesto a asumir con tus inversiones?\n",
      "*   **Diversificación**: ¿Tienes una cartera diversificada de inversiones en diferentes activos, como acciones, bonos y bienes raíces?\n",
      "\n",
      "**Preguntando al Cliente:**\n",
      "\n",
      "Antes de proceder con la acción sugerida, ¿estás seguro de que deseas invertir un parte de tu saldo actual?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for msg in chat_map[\"id_123\"].messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
